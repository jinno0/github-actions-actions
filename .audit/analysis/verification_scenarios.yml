version: "1.0"
run_id: "2026-02-08T04:40:00Z"

# === Core Function Verification Scenarios ===

scenarios:
  ### Scenario 1: Action構造の検証
  - function_id: "CF-STRUCT-001"
    name: "全Actionsの構造的完全性"
    description: "全13個のActionが正しく構造されていることを検証"

    test_method: "structural_validation"
    command: "pytest tests/ -v -k 'test_action'"

    expected_output:
      type: "test_result"
      total_tests: 455
      expected_pass: 455
      expected_fail: 0

    validation_rules:
      - "全てのaction.ymlがYAMLとしてパース可能"
      - "全てのActionでrequired inputsが定義されている"
      - "全てのActionでdescriptionが存在する"
      - "全てのActionでcomposite run typeが使用されている"
      - "全てのActionでbash shellが使用されている"

    actual_output:
      type: "test_result"
      total_tests: 455
      passed: 455
      failed: 0
      skipped: 2
      execution_time: "1.39s"

    passed: true
    interpretation: |
      全13個のActionが構造的に正しく実装されている。
      YAML構文、必須フィールド、ディレクトリ構造の検証をパスした。

  ### Scenario 2: テストカバレッジの検証
  - function_id: "QA-001"
    name: "テストカバレッジ >= 70%"

    test_method: "coverage_measurement"
    command: "pytest --cov=actions --cov=scripts --cov-report=term-missing"

    expected_output:
      type: "coverage_percentage"
      minimum: 70
      unit: "%"

    actual_output:
      type: "coverage_percentage"
      value: 92.99
      unit: "%"
      breakdown:
        total_statements: 927
        missed: 65
        covered: 862

    passed: true
    interpretation: |
      テストカバレッジ92.99%は目標の70%を大幅に上回っている。
      全体的なテスト品質は高い。
      一部で未カバレッジ領域があるが（generate_telemetry_report.pyの78.29%等）、

  ### Scenario 3: Integration Test Coverageの検証
  - function_id: "QA-003"
    name: "Integration Test Coverage 100%"

    test_method: "file_count"
    command: "find tests/integration -name 'test_*_integration.py' | wc -l"

    expected_output:
      type: "count"
      value: 13
      description: "全13個のActionにintegration testが存在"

    actual_output:
      type: "count"
      value: 13
      files:
        - "test_action_structure.py"
        - "test_review_and_merge_integration.py"
        - "test_auto_merge_integration.py"
        - "test_action_fixer_integration.py"
        - "test_auto_refactor_integration.py"
        - "test_bulk_merge_prs_integration.py"
        - "test_publish_pr_integration.py"
        - "test_auto_rebase_integration.py"
        - "test_auto_document_integration.py"
        - "test_bulk_rebase_prs_integration.py"
        - "test_pr_review_enqueuer_integration.py"
        - "test_release_notes_ai_integration.py"
        - "test_review_auto_merge_integration.py"
        - "test_spec_to_code_integration.py"

    passed: true
    interpretation: |
      全13個のActionに対してIntegration Testが作成されている。
      100%のActionレベルカバレッジを達成。

  ### Scenario 4: ドキュメントカバレッジの検証
  - function_id: "DOC-001"
    name: "全Actionsにドキュメントが存在"

    test_method: "file_count"
    command: "ls examples/*.yml instructions/*.md | wc -l"

    expected_output:
      type: "count"
      min_examples: 13
      min_instructions: 13

    actual_output:
      examples_count: 13
      instructions_count: 14
      completion_rate: 100%

    passed: true
    interpretation: |
      全Actionにexampleファイルとinstructionドキュメントが存在する。
      ドキュメント駆動開発の原則を遵守している。

  ### Scenario 5: AIレビュー品質メトリクスの検証（失敗例）
  - function_id: "QA-002"
    name: "AIレビュー受入率 >= 70%"

    test_method: "measurement"
    command: "python scripts/calculate_acceptance_rate.py --time-period 30d"

    expected_output:
      type: "percentage"
      minimum: 70
      unit: "%"

    actual_output:
      type: "error"
      error_message: "No review metrics data available"
      file_exists: false
      file_path: "metrics/review_metrics.json"

    passed: false
    interpretation: |
      CRITICAL: AIレビュー品質の核心的指標が測定できない。

      metrics/review_metrics.json が存在しないため、
      受入率を計測できない。これはプロジェクトの成功条件を
      検証できないことを意味する。

      即時のアクションが必要：
      1. パイロットプロジェクトでのレビューデータ収集開始
      2. データ収集プロセスの診断と修正
      3. 暫定ベースライン値の策定

  ### Scenario 6: テレメトリー収集の検証（失敗例）
  - function_id: "TEL-001"
    name: "テレメトリー収集が有効化されている"

    test_method: "file_check"
    command: "ls -la metrics/telemetry/"

    expected_output:
      type: "file_list"
      description: "テレメトリーデータファイルが存在する"

    actual_output:
      type: "empty_directory"
      file_count: 0
      directory_exists: true

    passed: false
    interpretation: |
      WARNING: テレメトリー機能は実装されているが、実際の収集が開始されていない。

      README.md:146-167 で「匿名テレメトリーを収集している」と記述しているが、
      現実は「収集準備完了」状態に留まっている。

      これは「使用状況を把握できない」「改善の優先順位を決定できない」等の
      問題を引き起こす。

  ### Scenario 7: Phase 3進捗の検証
  - function_id: "PHASE-001"
    name: "Phase 3: Stabilization & Adoptionの進捗"

    test_method: "manual_check"
    sources:
      - "PURPOSE.md"
      - "ADOPTION.md"

    expected_output:
      type: "progress_check"
      phase_3_tasks:
        - "各Actionの検証用ワークフローの作成"
        - "各Actionの導入ガイドの作成"
        - "組織内プロジェクトへの導入とフィードバック収集"
        - "ドキュメント（README）の整備"

    actual_output:
      type: "partial_completion"
      completed:
        - "検証用ワークフローの作成: ✅"
        - "導入ガイドの作成: ✅"
        - "ドキュメントの整備: ✅"
      in_progress:
        - "組織内プロジェクトへの導入: ⬜"
        - "フィードバック収集: ⬜"
      adopters_count: 0

    passed: false
    interpretation: |
      WARNING: Phase 3の「組織内導入」部分が進んでいない。

      ドキュメント整備は完了しているが、実際の採用事例が0件。
      これは以下の問題を示唆する：

      1. プロジェクトの認知度が不足している
      2. 導入ハードルが高い
      3. パイロット推進ができていない

      導入計画の実行が急務である。

## 検証結果のサマリー
summary:
  total_scenarios: 7
  passed: 4
  failed: 3
  pass_rate: 57.14%

  critical_failures:
    - "QA-002: AIレビュー受入率が測定できない"
    - "TEL-001: テレメトリー収集が開始されていない"
    - "PHASE-001: 組織内導入が進んでいない"

  successful_validations:
    - "CF-STRUCT-001: Action構造の完全性"
    - "QA-001: テストカバレッジ92.99%"
    - "QA-003: Integration Test Coverage 100%"
    - "DOC-001: ドキュメントカバレッジ100%"

## 全体的な判定
overall_assessment:
  status: "Conditional Pass"

  strengths:
    - "高品質な構造テスト（カバレッジ92.99%）"
    - "完全なドキュメントカバレッジ"
    - "13個のAI Actionsが実装完了"

  critical_gaps:
    - "AIの品質を測定できない（データなし）"
    - "実際の運用実績がない（導入0件）"
    - "機能検証が構造テストのみ"

  blocking_issues:
    - "パイロット導入が進んでいない"
    - "メトリクス収集が開始されていない"

  recommendation: |
    条件付き合格（Conditional Pass）。

    技術的基盤は整っているが、運用面での検証が不足している。
    以下のアクションを優先的に実施すること：

    優先度1（Critical）:
    1. パイロットプロジェクトでの導入開始
    2. AIレビューデータの収集と分析
    3. テレメトリー収集の有効化

    優先度2（High）:
    4. actツールによる機能検証の導入
    5. Claude CLIバージョン互換性テスト

    これらが完了すれば「Pass」に昇格可能。
