#!/usr/bin/env python3
"""
Core Function Verification Script for github-actions-actions
Generated by Repo Genesis Auditor v2.0

This script verifies the essential claims made by the repository:
1. All 13 Actions have proper structure (action.yml, templates, examples)
2. All Actions have corresponding instruction documents
3. Custom rules injection is supported
4. Dry run verification is implemented
"""

import json
import sys
from pathlib import Path
from dataclasses import dataclass, asdict
from typing import List, Dict, Any
import yaml


@dataclass
class VerificationResult:
    """Result of a single verification test"""
    function_id: str
    scenario_name: str
    passed: bool
    actual_output: Any
    expected_output: Any
    error_message: str | None = None
    interpretation: str = ""
    file_references: List[str] = None

    def __post_init__(self):
        if self.file_references is None:
            self.file_references = []


class GitHubActionsVerifier:
    """Verifies GitHub Actions repository structure and completeness"""

    def __init__(self, repo_root: Path):
        self.repo_root = repo_root
        self.actions_dir = repo_root / "actions"
        self.examples_dir = repo_root / "examples"
        self.instructions_dir = repo_root / "instructions"

    def verify_cf001_action_structure(self) -> VerificationResult:
        """
        CF-001: All 13 Actions have proper structure (action.yml, templates, examples)
        """
        expected_actions = [
            "review-and-merge",
            "spec-to-code",
            "action-fixer",
            "auto-refactor",
            "auto-document",
            "release-notes-ai",
            "auto-merge",
            "auto-rebase",
            "review-auto-merge",
            "publish-pr",
            "bulk-merge-prs",
            "bulk-rebase-prs",
            "pr-review-enqueuer"
        ]

        missing_actions = []
        incomplete_actions = []
        complete_actions = []

        for action_name in expected_actions:
            action_path = self.actions_dir / action_name
            action_yml = action_path / "action.yml"

            if not action_yml.exists():
                missing_actions.append(action_name)
                continue

            # Check for templates
            templates_dir = action_path / "templates"
            has_templates = templates_dir.exists() and list(templates_dir.glob("*.txt"))

            # Check for example
            example_files = list(self.examples_dir.glob(f"{action_name}*.yml"))
            has_example = len(example_files) > 0

            # Check for instruction
            instruction_files = list(self.instructions_dir.glob(f"{action_name}.md"))
            has_instruction = len(instruction_files) > 0

            if has_templates and has_example and has_instruction:
                complete_actions.append(action_name)
            else:
                incomplete_actions.append({
                    "name": action_name,
                    "has_templates": has_templates,
                    "has_example": has_example,
                    "has_instruction": has_instruction
                })

        passed = len(missing_actions) == 0 and len(incomplete_actions) == 0

        return VerificationResult(
            function_id="CF-001",
            scenario_name="All 13 Actions have proper structure",
            passed=passed,
            actual_output={
                "total_expected": len(expected_actions),
                "complete_actions": len(complete_actions),
                "incomplete_actions": len(incomplete_actions),
                "missing_actions": len(missing_actions),
                "details": {
                    "complete": complete_actions,
                    "incomplete": incomplete_actions,
                    "missing": missing_actions
                }
            },
            expected_output={
                "total_expected": 13,
                "complete_actions": 13,
                "incomplete_actions": 0,
                "missing_actions": 0
            },
            interpretation=(
                f"全13件のActionのうち、{len(complete_actions)}件が完全な構造を持つ"
                if passed
                else f"{len(missing_actions)}件のActionが存在せず、{len(incomplete_actions)}件の構造が不完全"
            ),
            file_references=[str(action) for action in complete_actions]
        )

    def verify_cf002_yaml_syntax(self) -> VerificationResult:
        """
        CF-002: All action.yml files have valid YAML syntax
        """
        action_yml_files = list(self.actions_dir.glob("*/action.yml"))
        valid_files = []
        invalid_files = []

        for action_yml in action_yml_files:
            try:
                with open(action_yml, 'r') as f:
                    yaml.safe_load(f)
                valid_files.append(action_yml.parent.name)
            except yaml.YAMLError as e:
                invalid_files.append({
                    "action": action_yml.parent.name,
                    "error": str(e)
                })

        passed = len(invalid_files) == 0

        return VerificationResult(
            function_id="CF-002",
            scenario_name="All action.yml files have valid YAML syntax",
            passed=passed,
            actual_output={
                "total_files": len(action_yml_files),
                "valid_files": len(valid_files),
                "invalid_files": len(invalid_files),
                "invalid_details": invalid_files
            },
            expected_output={
                "total_files": len(action_yml_files),
                "valid_files": len(action_yml_files),
                "invalid_files": 0
            },
            interpretation=(
                f"全{len(action_yml_files)}件のaction.ymlが有効なYAML構文"
                if passed
                else f"{len(invalid_files)}件のaction.ymlにYAML構文エラー"
            ),
            file_references=[str(f) for f in valid_files]
        )

    def verify_cf003_custom_rules_support(self) -> VerificationResult:
        """
        CF-003: Custom rules injection is supported
        """
        # Check if review-and-merge has custom rules functionality
        review_merge_dir = self.actions_dir / "review-and-merge"
        action_yml = review_merge_dir / "action.yml"

        if not action_yml.exists():
            return VerificationResult(
                function_id="CF-003",
                scenario_name="Custom rules injection is supported",
                passed=False,
                actual_output=None,
                expected_output="review-and-merge/action.yml with custom-rules-path input",
                error_message="review-and-merge action not found",
                interpretation="review-and-merge Actionが存在しない"
            )

        with open(action_yml, 'r') as f:
            content = f.read()

        # Check for custom-rules-path input
        has_custom_rules_input = "custom-rules-path:" in content or "custom_rules_path:" in content

        # Check for custom rules templates
        custom_rules_dir = self.examples_dir / "custom-rules"
        custom_rule_templates = list(custom_rules_dir.glob("*.md")) if custom_rules_dir.exists() else []

        # Check for custom rules instruction
        custom_rules_instruction = self.instructions_dir / "review-and-merge-custom-rules.md"

        passed = (
            has_custom_rules_input and
            len(custom_rule_templates) > 0 and
            custom_rules_instruction.exists()
        )

        return VerificationResult(
            function_id="CF-003",
            scenario_name="Custom rules injection is supported",
            passed=passed,
            actual_output={
                "has_custom_rules_input": has_custom_rules_input,
                "custom_rule_templates_count": len(custom_rule_templates),
                "custom_rule_templates": [t.name for t in custom_rule_templates],
                "has_custom_rules_instruction": custom_rules_instruction.exists()
            },
            expected_output={
                "has_custom_rules_input": True,
                "custom_rule_templates_count": 4,  # TypeScript, Python, React, Security
                "has_custom_rules_instruction": True
            },
            interpretation=(
                f"カスタムルール注入機能が実装されている（{len(custom_rule_templates)}個のテンプレート存在）"
                if passed
                else "カスタムルール注入機能が不完全または未実装"
            ),
            file_references=[
                str(action_yml),
                str(custom_rules_instruction)
            ] + [str(t) for t in custom_rule_templates]
        )

    def verify_cf004_dry_run_verification(self) -> VerificationResult:
        """
        CF-004: Dry run verification is implemented
        """
        # Check for test infrastructure
        tests_dir = self.repo_root / "tests"
        test_files = list(tests_dir.glob("test_*.py")) if tests_dir.exists() else []

        # Check for test workflow
        test_workflow = self.repo_root / ".github" / "workflows" / "test-with-dry-run.yml"

        # Check for TESTING.md documentation
        testing_doc = self.repo_root / "TESTING.md"

        # Check if test files import pytest
        uses_pytest = False
        for test_file in test_files:
            try:
                with open(test_file, 'r') as f:
                    if 'import pytest' in f.read():
                        uses_pytest = True
                        break
            except:
                pass

        passed = (
            len(test_files) > 0 and
            test_workflow.exists() and
            testing_doc.exists() and
            uses_pytest
        )

        return VerificationResult(
            function_id="CF-004",
            scenario_name="Dry run verification is implemented",
            passed=passed,
            actual_output={
                "test_files_count": len(test_files),
                "test_workflow_exists": test_workflow.exists(),
                "testing_doc_exists": testing_doc.exists(),
                "uses_pytest": uses_pytest
            },
            expected_output={
                "test_files_count": 13,  # At least one test per action
                "test_workflow_exists": True,
                "testing_doc_exists": True,
                "uses_pytest": True
            },
            interpretation=(
                f"Dry Run検証が実装されている（{len(test_files)}個のテストファイル存在）"
                if passed
                else "Dry Run検証が不完全または未実装"
            ),
            file_references=[
                str(test_workflow),
                str(testing_doc)
            ] + [str(f) for f in test_files[:5]]  # Limit to first 5
        )

    def verify_cf005_instruction_coverage(self) -> VerificationResult:
        """
        CF-005: All Actions have corresponding instruction documents
        """
        expected_actions = [
            "review-and-merge",
            "spec-to-code",
            "action-fixer",
            "auto-refactor",
            "auto-document",
            "release-notes-ai",
            "auto-merge",
            "auto-rebase",
            "review-auto-merge",
            "publish-pr",
            "bulk-merge-prs",
            "bulk-rebase-prs",
            "pr-review-enqueuer"
        ]

        instructions_with_docs = []
        instructions_without_docs = []

        for action_name in expected_actions:
            instruction_file = self.instructions_dir / f"{action_name}.md"
            if instruction_file.exists():
                instructions_with_docs.append(action_name)
            else:
                instructions_without_docs.append(action_name)

        passed = len(instructions_without_docs) == 0

        return VerificationResult(
            function_id="CF-005",
            scenario_name="All Actions have corresponding instruction documents",
            passed=passed,
            actual_output={
                "total_actions": len(expected_actions),
                "with_docs": len(instructions_with_docs),
                "without_docs": len(instructions_without_docs),
                "missing_docs": instructions_without_docs
            },
            expected_output={
                "total_actions": 13,
                "with_docs": 13,
                "without_docs": 0
            },
            interpretation=(
                f"全{len(expected_actions)}件のActionに導入ガイドが存在"
                if passed
                else f"{len(instructions_without_docs)}件のActionに導入ガイドが欠落"
            ),
            file_references=[str(self.instructions_dir / f"{action}.md") for action in instructions_with_docs]
        )

    def verify_cf006_example_coverage(self) -> VerificationResult:
        """
        CF-006: All Actions have corresponding example workflows
        """
        expected_actions = [
            "review-and-merge",
            "spec-to-code",
            "action-fixer",
            "auto-refactor",
            "auto-document",
            "release-notes-ai",
            "auto-merge",
            "auto-rebase",
            "review-auto-merge",
            "publish-pr",
            "bulk-merge-prs",
            "bulk-rebase-prs",
            "pr-review-enqueuer"
        ]

        actions_with_examples = []
        actions_without_examples = []

        for action_name in expected_actions:
            example_files = list(self.examples_dir.glob(f"{action_name}*.yml"))
            if len(example_files) > 0:
                actions_with_examples.append(action_name)
            else:
                actions_without_examples.append(action_name)

        passed = len(actions_without_examples) == 0

        return VerificationResult(
            function_id="CF-006",
            scenario_name="All Actions have corresponding example workflows",
            passed=passed,
            actual_output={
                "total_actions": len(expected_actions),
                "with_examples": len(actions_with_examples),
                "without_examples": len(actions_without_examples),
                "missing_examples": actions_without_examples
            },
            expected_output={
                "total_actions": 13,
                "with_examples": 13,
                "without_examples": 0
            },
            interpretation=(
                f"全{len(expected_actions)}件のActionに利用例が存在"
                if passed
                else f"{len(actions_without_examples)}件のActionに利用例が欠落"
            ),
            file_references=[str(self.examples_dir / f"{action}.yml") for action in actions_with_examples]
        )


def main():
    """Run all core function verifications and generate report"""
    repo_root = Path(__file__).parent.parent.parent
    verifier = GitHubActionsVerifier(repo_root)

    print("=" * 80)
    print("CORE FUNCTION VERIFICATION REPORT")
    print("=" * 80)
    print(f"Repository: {repo_root}")
    print(f"Generated by: Repo Genesis Auditor v2.0")
    print("=" * 80)
    print()

    results = [
        verifier.verify_cf001_action_structure(),
        verifier.verify_cf002_yaml_syntax(),
        verifier.verify_cf003_custom_rules_support(),
        verifier.verify_cf004_dry_run_verification(),
        verifier.verify_cf005_instruction_coverage(),
        verifier.verify_cf006_example_coverage(),
    ]

    passed_count = sum(1 for r in results if r.passed)
    total_count = len(results)

    for r in results:
        status = "✅ PASS" if r.passed else "❌ FAIL"
        print(f"{status} [{r.function_id}] {r.scenario_name}")
        print(f"  解釈: {r.interpretation}")
        if r.error_message:
            print(f"  エラー: {r.error_message}")
        if not r.passed and r.actual_output:
            print(f"  実測値: {json.dumps(r.actual_output, ensure_ascii=False, indent=2)}")
        print()

    print("=" * 80)
    print(f"SUMMARY: {passed_count}/{total_count} passed")
    print("=" * 80)

    if passed_count == total_count:
        print("判定: ✅ リポジトリの存在意義が検証された")
        print("   全ての中核機能が適切に実装されている")
    else:
        print("判定: ⚠️  存在意義の一部に改善の余地あり")
        print()
        print("主な課題:")
        for r in results:
            if not r.passed:
                print(f"  - {r.function_id}: {r.interpretation}")

    # Save results to JSON
    output_path = Path(__file__).parent.parent / "output" / "verification_result.json"
    output_path.parent.mkdir(parents=True, exist_ok=True)

    results_dict = [asdict(r) for r in results]
    output_path.write_text(
        json.dumps(results_dict, ensure_ascii=False, indent=2),
        encoding='utf-8'
    )

    print()
    print(f"詳細な検証結果を保存しました: {output_path}")

    sys.exit(0 if passed_count == total_count else 1)


if __name__ == "__main__":
    main()
