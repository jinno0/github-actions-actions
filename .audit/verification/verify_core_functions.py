#!/usr/bin/env python3
"""
Core Function Verification Script
Generated by Repo Genesis Auditor

This script verifies the core functions claimed by the github-actions-actions repository.
It tests whether the repository actually provides what it claims to provide.
"""

import json
import subprocess
import sys
from pathlib import Path
from dataclasses import dataclass, asdict
from typing import Any, List, Optional


@dataclass
class VerificationResult:
    function_id: str
    scenario_name: str
    passed: bool
    actual_output: Any
    expected_output: Any
    error_message: Optional[str] = None
    interpretation: str = ""
    evidence: List[str] = None

    def __post_init__(self):
        if self.evidence is None:
            self.evidence = []


def verify_cf001_action_count_and_structure() -> VerificationResult:
    """
    CF-001: 13種類のAI Actionsを提供しており、それぞれがexamplesとinstructionsを持つ
    """
    try:
        repo_root = Path("/home/jinno/github-actions-actions")
        actions_dir = repo_root / "actions"
        examples_dir = repo_root / "examples"
        instructions_dir = repo_root / "instructions"

        # Count actions with action.yml
        action_yml_files = list(actions_dir.glob("*/action.yml"))
        actual_count = len(action_yml_files)

        # Verify each action has example and instruction
        missing_examples = []
        missing_instructions = []

        for action_yml in action_yml_files:
            action_name = action_yml.parent.name
            example_file = examples_dir / f"{action_name}-example.yml"
            instruction_file = instructions_dir / f"{action_name}.md"

            if not example_file.exists():
                missing_examples.append(action_name)
            if not instruction_file.exists():
                missing_instructions.append(action_name)

        expected_count = 13
        passed = (actual_count == expected_count and
                 len(missing_examples) == 0 and
                 len(missing_instructions) == 0)

        return VerificationResult(
            function_id="CF-001",
            scenario_name="13種類のAI Actionsの存在と構造",
            passed=passed,
            actual_output={
                "action_count": actual_count,
                "actions_with_examples": actual_count - len(missing_examples),
                "actions_with_instructions": actual_count - len(missing_instructions),
                "missing_examples": missing_examples,
                "missing_instructions": missing_instructions
            },
            expected_output={
                "action_count": 13,
                "actions_with_examples": 13,
                "actions_with_instructions": 13
            },
            interpretation=(
                f"✅ {actual_count}個のActionが存在し、全てがexamplesとinstructionsを持っている"
                if passed else
                f"❌ Action数: {actual_count}（期待: {expected_count}）、"
                f"example缺失: {len(missing_examples)}、instruction缺失: {len(missing_instructions)}"
            ),
            evidence=[f"Found {actual_count} action.yml files in actions/"]
        )

    except Exception as e:
        return VerificationResult(
            function_id="CF-001",
            scenario_name="13種類のAI Actionsの存在と構造",
            passed=False,
            actual_output=None,
            expected_output={"action_count": 13},
            error_message=str(e),
            interpretation="構造チェック中にエラーが発生"
        )


def verify_cf002_composite_actions() -> VerificationResult:
    """
    CF-002: 全てのActionがComposite Actionとして実装されている
    """
    try:
        repo_root = Path("/home/jinno/github-actions-actions")
        actions_dir = repo_root / "actions"

        action_yml_files = list(actions_dir.glob("*/action.yml"))

        non_composite = []
        composite_actions = []

        for action_yml in action_yml_files:
            import yaml
            with open(action_yml) as f:
                content = yaml.safe_load(f)

            # Check if it's a composite action
            runs = content.get("runs", {})
            using = runs.get("using", "")

            if using == "composite":
                composite_actions.append(action_yml.parent.name)
            else:
                non_composite.append({
                    "name": action_yml.parent.name,
                    "using": using
                })

        passed = len(non_composite) == 0

        return VerificationResult(
            function_id="CF-002",
            scenario_name="全ActionがComposite Actionとして実装",
            passed=passed,
            actual_output={
                "composite_count": len(composite_actions),
                "non_composite": non_composite
            },
            expected_output={
                "composite_count": len(action_yml_files),
                "non_composite": []
            },
            interpretation=(
                f"✅ 全{len(composite_actions)}個のActionがComposite Actionとして実装されている"
                if passed else
                f"❌ {len(non_composite)}個のActionがComposite Actionではない"
            ),
            evidence=composite_actions
        )

    except Exception as e:
        return VerificationResult(
            function_id="CF-002",
            scenario_name="全ActionがComposite Actionとして実装",
            passed=False,
            actual_output=None,
            expected_output={"composite_count": 13},
            error_message=str(e),
            interpretation="Composite Actionチェック中にエラーが発生"
        )


def verify_cf003_dry_run_validation() -> VerificationResult:
    """
    CF-003: 各ActionはDry Runモードで自動検証される
    """
    try:
        repo_root = Path("/home/jinno/github-actions-actions")
        test_workflow = repo_root / ".github" / "workflows" / "test-all-actions.yml"

        if not test_workflow.exists():
            return VerificationResult(
                function_id="CF-003",
                scenario_name="Dry Run検証ワークフローの存在",
                passed=False,
                actual_output=None,
                expected_output={"workflow_exists": True},
                error_message="test-all-actions.ymlが見つからない",
                interpretation="❌ Dry Run検証用ワークフローが存在しない"
            )

        import yaml
        with open(test_workflow) as f:
            workflow = yaml.safe_load(f)

        # Check if workflow has proper triggers
        triggers = workflow.get("on", {})
        has_pr_trigger = "pull_request" in triggers
        has_push_trigger = "push" in triggers

        # Check if it tests actions
        jobs = workflow.get("jobs", {})
        has_test_job = "test-action" in jobs or "test" in jobs

        # Check for dry-run environment variable
        uses_dry_run = False
        if has_test_job:
            test_job = jobs.get("test-action", jobs.get("test", {}))
            steps = test_job.get("steps", [])
            for step in steps:
                env = step.get("env", {})
                if "DRY_RUN" in env or "dry-run" in str(env):
                    uses_dry_run = True
                    break

        passed = test_workflow.exists() and has_test_job

        return VerificationResult(
            function_id="CF-003",
            scenario_name="Dry Run検証ワークフローの実装",
            passed=passed,
            actual_output={
                "workflow_exists": True,
                "has_pr_trigger": has_pr_trigger,
                "has_push_trigger": has_push_trigger,
                "has_test_job": has_test_job,
                "uses_dry_run_env": uses_dry_run
            },
            expected_output={
                "workflow_exists": True,
                "has_test_job": True
            },
            interpretation=(
                f"✅ Dry Run検証ワークフローが存在し、自動テストを実装している"
                if passed else
                f"⚠️ ワークフローは存在するが、テスト構成が不完全"
            ),
            evidence=[".github/workflows/test-all-actions.yml"]
        )

    except Exception as e:
        return VerificationResult(
            function_id="CF-003",
            scenario_name="Dry Run検証ワークフローの実装",
            passed=False,
            actual_output=None,
            expected_output={"workflow_exists": True},
            error_message=str(e),
            interpretation="Dry Run検証チェック中にエラーが発生"
        )


def verify_cf004_acceptance_rate_tracking() -> VerificationResult:
    """
    CF-004: AIレビューの品質メトリクス（受入率）を追跡できる
    """
    try:
        repo_root = Path("/home/jinno/github-actions-actions")
        script_path = repo_root / "scripts" / "calculate_acceptance_rate.py"

        if not script_path.exists():
            return VerificationResult(
                function_id="CF-004",
                scenario_name="受入率計算スクリプトの実行可能性",
                passed=False,
                actual_output=None,
                expected_output={"script_exists": True, "executable": True},
                error_message="calculate_acceptance_rate.pyが見つからない",
                interpretation="❌ 受入率計算スクリプトが存在しない"
            )

        # Test if script is executable
        result = subprocess.run(
            ["python3", str(script_path), "--help"],
            capture_output=True,
            text=True,
            timeout=10
        )

        executable = result.returncode == 0
        has_help_output = "usage: calculate_acceptance_rate.py" in result.stdout

        # Check for metrics data
        metrics_dir = repo_root / "metrics"
        has_metrics_data = False
        metrics_files = []
        if metrics_dir.exists():
            metrics_files = list(metrics_dir.glob("acceptance_rate*.json"))
            has_metrics_data = len(metrics_files) > 0

        passed = executable and has_help_output

        return VerificationResult(
            function_id="CF-004",
            scenario_name="受入率計算スクリプトの実行可能性",
            passed=passed,
            actual_output={
                "script_exists": True,
                "executable": executable,
                "has_help_output": has_help_output,
                "has_metrics_data": has_metrics_data,
                "metrics_files": [f.name for f in metrics_files]
            },
            expected_output={
                "script_exists": True,
                "executable": True
            },
            interpretation=(
                f"✅ 受入率計算スクリプトが実行可能" +
                (f"（メトリクスデータ: {len(metrics_files)}ファイル）" if has_metrics_data else "（メトリクスデータなし）")
                if passed else
                "❌ スクリプトが実行不可能"
            ),
            evidence=[str(script_path)]
        )

    except Exception as e:
        return VerificationResult(
            function_id="CF-004",
            scenario_name="受入率計算スクリプトの実行可能性",
            passed=False,
            actual_output=None,
            expected_output={"script_exists": True, "executable": True},
            error_message=str(e),
            interpretation="受入率計算スクリプトチェック中にエラーが発生"
        )


def verify_yaml_syntax_validity() -> VerificationResult:
    """
    QA-002: 全てのaction.ymlが有効なYAMLとしてパース可能
    """
    try:
        repo_root = Path("/home/jinno/github-actions-actions")
        actions_dir = repo_root / "actions"

        action_yml_files = list(actions_dir.glob("*/action.yml"))

        invalid_files = []
        valid_files = []

        for action_yml in action_yml_files:
            try:
                import yaml
                with open(action_yml) as f:
                    yaml.safe_load(f)
                valid_files.append(action_yml.parent.name)
            except Exception as e:
                invalid_files.append({
                    "name": action_yml.parent.name,
                    "error": str(e)
                })

        passed = len(invalid_files) == 0

        return VerificationResult(
            function_id="QA-002",
            scenario_name="YAML構文の妥当性",
            passed=passed,
            actual_output={
                "total_files": len(action_yml_files),
                "valid_files": len(valid_files),
                "invalid_files": invalid_files
            },
            expected_output={
                "total_files": len(action_yml_files),
                "valid_files": len(action_yml_files),
                "invalid_files": []
            },
            interpretation=(
                f"✅ 全{len(valid_files)}個のaction.ymlが有効なYAML"
                if passed else
                f"❌ {len(invalid_files)}個のファイルにYAML構文エラー"
            ),
            evidence=valid_files
        )

    except Exception as e:
        return VerificationResult(
            function_id="QA-002",
            scenario_name="YAML構文の妥当性",
            passed=False,
            actual_output=None,
            expected_output={"invalid_files": []},
            error_message=str(e),
            interpretation="YAML構文チェック中にエラーが発生"
        )


def main():
    """全Core Functionを検証し、レポートを生成"""

    print("=" * 80)
    print("CORE FUNCTION VERIFICATION REPORT")
    print("=" * 80)
    print(f"Repository: github-actions-actions")
    print(f"Timestamp: 2026-02-03T23:20:15Z")
    print()

    results = [
        verify_cf001_action_count_and_structure(),
        verify_cf002_composite_actions(),
        verify_cf003_dry_run_validation(),
        verify_cf004_acceptance_rate_tracking(),
        verify_yaml_syntax_validity(),
    ]

    # Generate text report
    passed_count = sum(1 for r in results if r.passed)
    total_count = len(results)

    for r in results:
        status = "✅ PASS" if r.passed else "❌ FAIL"
        print(f"\n{status} [{r.function_id}] {r.scenario_name}")
        print(f"  解釈: {r.interpretation}")
        if r.error_message:
            print(f"  エラー: {r.error_message}")
        if r.evidence:
            print(f"  エビデンス: {', '.join(r.evidence[:3])}")

    print("\n" + "=" * 80)
    print(f"SUMMARY: {passed_count}/{total_count} passed")

    if passed_count == total_count:
        print("判定: ✅ リポジトリの存在意義が検証された")
        print("\n全てのコア機能が正しく実装されています。")
    else:
        print("判定: ⚠️ 一部のコア機能に問題があります")
        print("\n次のアクション:")
        for r in results:
            if not r.passed:
                print(f"  - {r.function_id}: {r.interpretation}")

    # Save results to JSON
    output_path = Path("/home/jinno/github-actions-actions/.audit/output/verification_result.json")
    output_path.parent.mkdir(parents=True, exist_ok=True)

    # Convert dataclass to dict for JSON serialization
    results_dict = [asdict(r) for r in results]

    output_path.write_text(
        json.dumps(results_dict, ensure_ascii=False, indent=2),
        encoding="utf-8"
    )

    print(f"\n詳細結果を保存しました: {output_path}")

    sys.exit(0 if passed_count == total_count else 1)


if __name__ == "__main__":
    main()
