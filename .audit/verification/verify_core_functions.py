#!/usr/bin/env python3
"""
Core Function Verification Script
Generated by Repo Genesis Auditor v2.0

This script verifies the repository's core functions and quality attributes
as defined in .audit/config/intent.yml
"""

import json
import subprocess
import sys
from pathlib import Path
from dataclasses import dataclass, asdict
from typing import Any, List, Dict
import yaml


@dataclass
class VerificationResult:
    """検証結果を表すデータクラス"""
    function_id: str
    scenario_name: str
    passed: bool
    actual_output: Any
    expected_output: Any
    error_message: str | None = None
    interpretation: str = ""
    file_references: List[str] = None

    def __post_init__(self):
        if self.file_references is None:
            self.file_references = []


def verify_cf001_action_count() -> VerificationResult:
    """CF-001: 13種類のAI Actionsを提供している"""

    try:
        # actions/ディレクトリ以下のaction.ymlファイルをカウント
        action_files = list(Path("actions").glob("*/action.yml"))

        # _shared と lib を除外
        valid_actions = [
            f.parent.name for f in action_files
            if f.parent.name not in ["_shared", "lib"]
        ]

        # 期待されるActionリスト
        expected_actions = {
            "action-fixer", "auto-document", "auto-merge", "auto-rebase",
            "auto-refactor", "bulk-merge-prs", "bulk-rebase-prs",
            "pr-review-enqueuer", "publish-pr", "release-notes-ai",
            "review-and-merge", "review-auto-merge", "spec-to-code"
        }

        actual_count = len(valid_actions)
        expected_count = 13
        passed = actual_count == expected_count and set(valid_actions) == expected_actions

        return VerificationResult(
            function_id="CF-001",
            scenario_name="13種類のAI Actionsを提供している",
            passed=passed,
            actual_output={"count": actual_count, "actions": sorted(valid_actions)},
            expected_output={"count": expected_count, "actions": sorted(expected_actions)},
            interpretation=(
                f"✅ {actual_count}個のActionが存在し、期待通り" if passed
                else f"❌ 期待値{expected_count}個に対し、実際は{actual_count}個。"
                   f"不足: {expected_actions - set(valid_actions)}, "
                   f"余剰: {set(valid_actions) - expected_actions}"
            ),
            file_references=[str(f) for f in action_files]
        )

    except Exception as e:
        return VerificationResult(
            function_id="CF-001",
            scenario_name="13種類のAI Actionsを提供している",
            passed=False,
            actual_output=None,
            expected_output={"count": 13},
            error_message=str(e),
            interpretation="actions/ディレクトリのスキャンに失敗。ディレクトリ構造を確認せよ。"
        )


def verify_cf002_documentation_coverage() -> VerificationResult:
    """CF-002: 全Actionに対してExample WorkflowとInstruction Guideを提供している"""

    try:
        # Action一覧を取得
        action_dirs = [d.name for d in Path("actions").iterdir()
                      if d.is_dir() and d.name not in ["_shared", "lib"]]

        # ExampleとInstructionをチェック
        examples = [f.stem.replace("-example", "") for f in Path("examples").glob("*.yml")
                   if "custom-rules" not in str(f)]
        instructions = [f.stem for f in Path("instructions").glob("*.md")
                       if "custom-rules" not in str(f)]

        missing_examples = []
        missing_instructions = []

        for action in action_dirs:
            # review-and-merge は custom-rules を持つが、それは別扱い
            if action == "review-and-merge":
                has_example = any(action in e for e in examples)
                has_instruction = any(action in i or "review-and-merge-custom-rules" in i
                                    for i in instructions)
            else:
                has_example = action in examples
                has_instruction = action in instructions

            if not has_example:
                missing_examples.append(action)
            if not has_instruction:
                missing_instructions.append(action)

        passed = len(missing_examples) == 0 and len(missing_instructions) == 0

        return VerificationResult(
            function_id="CF-002",
            scenario_name="全ActionのExampleとInstructionの対応",
            passed=passed,
            actual_output={
                "total_actions": len(action_dirs),
                "missing_examples": missing_examples,
                "missing_instructions": missing_instructions
            },
            expected_output={
                "total_actions": len(action_dirs),
                "missing_examples": [],
                "missing_instructions": []
            },
            interpretation=(
                "✅ 全ActionにExampleとInstructionが存在" if passed
                else f"❌ 不足ドキュメント: Examples={missing_examples}, "
                   f"Instructions={missing_instructions}"
            )
        )

    except Exception as e:
        return VerificationResult(
            function_id="CF-002",
            scenario_name="全ActionのExampleとInstructionの対応",
            passed=False,
            actual_output=None,
            expected_output={"missing_examples": [], "missing_instructions": []},
            error_message=str(e),
            interpretation="ドキュメントのスキャンに失敗。"
        )


def verify_cf005_dry_run_validation() -> VerificationResult:
    """CF-005: Dry Runモードによる自動検証が可能"""

    try:
        workflow_file = Path(".github/workflows/test-with-dry-run.yml")

        if not workflow_file.exists():
            return VerificationResult(
                function_id="CF-005",
                scenario_name="Dry Run検証ワークフローの存在",
                passed=False,
                actual_output=None,
                expected_output="test-with-dry-run.yml が存在",
                error_message="ワークフローファイルが見つからない",
                interpretation="Dry Run検証用ワークフローが見つからない。"
            )

        # YAML構文チェック
        with open(workflow_file) as f:
            workflow_content = yaml.safe_load(f)

        # 構造チェック
        has_jobs = "jobs" in workflow_content
        job_names = list(workflow_content.get("jobs", {}).keys()) if has_jobs else []

        return VerificationResult(
            function_id="CF-005",
            scenario_name="Dry Run検証ワークフローの存在",
            passed=has_jobs and len(job_names) > 0,
            actual_output={"exists": True, "jobs": job_names},
            expected_output={"exists": True, "jobs": ["*"]},
            interpretation=(
                f"✅ Dry Run検証ワークフローが存在（{len(job_names)}個のジョブ）"
                if has_jobs
                else "❌ ワークフローファイルが不正"
            ),
            file_references=[str(workflow_file)]
        )

    except Exception as e:
        return VerificationResult(
            function_id="CF-005",
            scenario_name="Dry Run検証ワークフローの存在",
            passed=False,
            actual_output=None,
            expected_output="有効なYAMLワークフロー",
            error_message=str(e),
            interpretation="ワークフローファイルの検証に失敗。"
        )


def verify_cf006_telemetry_privacy() -> VerificationResult:
    """CF-006: プライバシーを考慮したテレメトリー収集"""

    try:
        script_file = Path("scripts/collect_metrics.py")

        if not script_file.exists():
            return VerificationResult(
                function_id="CF-006",
                scenario_name="テレメトリーのプライバシー機能",
                passed=False,
                actual_output=None,
                expected_output="collect_metrics.py が存在",
                error_message="スクリプトが見つからない",
                interpretation="テレメトリー収集スクリプトが見つからない。"
            )

        script_content = script_file.read_text()

        # プライバシー機能のチェック
        has_opt_out = "DISABLE_TELEMETRY" in script_content
        has_hashing = "hashlib" in script_content or "sha256" in script_content
        has_anonymization = "hash" in script_content.lower()

        passed = has_opt_out and has_hashing and has_anonymization

        return VerificationResult(
            function_id="CF-006",
            scenario_name="テレメトリーのプライバシー機能",
            passed=passed,
            actual_output={
                "opt_out": has_opt_out,
                "hashing": has_hashing,
                "anonymization": has_anonymization
            },
            expected_output={
                "opt_out": True,
                "hashing": True,
                "anonymization": True
            },
            interpretation=(
                "✅ プライバシー機能（オプトアウト、匿名化、ハッシュ化）が実装されている"
                if passed
                else "❌ 一部のプライバシー機能が欠落している"
            ),
            file_references=[str(script_file)]
        )

    except Exception as e:
        return VerificationResult(
            function_id="CF-006",
            scenario_name="テレメトリーのプライバシー機能",
            passed=False,
            actual_output=None,
            expected_output={"opt_out": True, "hashing": True, "anonymization": True},
            error_message=str(e),
            interpretation="スクリプトの検証に失敗。"
        )


def verify_cf007_acceptance_rate_tracking() -> VerificationResult:
    """CF-007: AIレビュー品質メトリクス（受入率）の追跡"""

    try:
        script_file = Path("scripts/calculate_acceptance_rate.py")
        lib_file = Path("actions/lib/acceptance_tracker.py")

        script_exists = script_file.exists()
        lib_exists = lib_file.exists()

        if script_exists:
            script_content = script_file.read_text()
            has_calculation = "acceptance_rate" in script_content.lower()
            has_output = "print" in script_content or "json" in script_content
        else:
            has_calculation = False
            has_output = False

        passed = script_exists and lib_exists and has_calculation and has_output

        return VerificationResult(
            function_id="CF-007",
            scenario_name="受入率計算スクリプトの実装",
            passed=passed,
            actual_output={
                "script_exists": script_exists,
                "lib_exists": lib_exists,
                "has_calculation": has_calculation,
                "has_output": has_output
            },
            expected_output={
                "script_exists": True,
                "lib_exists": True,
                "has_calculation": True,
                "has_output": True
            },
            interpretation=(
                "✅ 受入率計算スクリプトとライブラリが実装されている"
                if passed
                else "❌ 受入率計算機能が不完全または欠落"
            ),
            file_references=[
                str(script_file) if script_exists else None,
                str(lib_file) if lib_exists else None
            ]
        )

    except Exception as e:
        return VerificationResult(
            function_id="CF-007",
            scenario_name="受入率計算スクリプトの実装",
            passed=False,
            actual_output=None,
            expected_output={"script_exists": True, "lib_exists": True},
            error_message=str(e),
            interpretation="受入率計算機能の検証に失敗。"
        )


def verify_qa002_documentation_completeness() -> VerificationResult:
    """QA-002: ドキュメントカバレッジ（構造チェック）"""

    try:
        actions_path = Path("actions")
        instructions_path = Path("instructions")

        action_dirs = [d for d in actions_path.iterdir()
                      if d.is_dir() and d.name not in ["_shared", "lib"]]

        missing_readmes = []
        missing_instructions = []

        for action_dir in action_dirs:
            action_name = action_dir.name
            readme_file = action_dir / "README.md"
            instruction_file = instructions_path / f"{action_name}.md"

            if not readme_file.exists():
                missing_readmes.append(action_name)
            if not instruction_file.exists():
                missing_instructions.append(action_name)

        passed = len(missing_readmes) == 0 and len(missing_instructions) == 0

        return VerificationResult(
            function_id="QA-002",
            scenario_name="全Actionのドキュメントカバレッジ",
            passed=passed,
            actual_output={
                "total_actions": len(action_dirs),
                "missing_readmes": missing_readmes,
                "missing_instructions": missing_instructions
            },
            expected_output={
                "total_actions": len(action_dirs),
                "missing_readmes": [],
                "missing_instructions": []
            },
            interpretation=(
                f"✅ 全{len(action_dirs)}個のActionにREADMEとInstructionが存在"
                if passed
                else f"❌ 不足: README={missing_readmes}, Instruction={missing_instructions}"
            )
        )

    except Exception as e:
        return VerificationResult(
            function_id="QA-002",
            scenario_name="全Actionのドキュメントカバレッジ",
            passed=False,
            actual_output=None,
            expected_output={"missing_readmes": [], "missing_instructions": []},
            error_message=str(e),
            interpretation="ドキュメントカバレッジのチェックに失敗。"
        )


def main():
    """全Core Functionを検証し、レポートを生成"""

    print("=" * 80)
    print("CORE FUNCTION VERIFICATION REPORT")
    print("Repo Genesis Auditor v2.0")
    print("=" * 80)
    print()

    # 検証関数のリスト
    verification_functions = [
        verify_cf001_action_count,
        verify_cf002_documentation_coverage,
        verify_cf005_dry_run_validation,
        verify_cf006_telemetry_privacy,
        verify_cf007_acceptance_rate_tracking,
        verify_qa002_documentation_completeness,
    ]

    results = []
    for verify_func in verification_functions:
        try:
            result = verify_func()
            results.append(result)

            status = "✅ PASS" if result.passed else "❌ FAIL"
            print(f"{status} [{result.function_id}] {result.scenario_name}")
            print(f"  解釈: {result.interpretation}")
            if result.error_message:
                print(f"  エラー: {result.error_message}")
            print()

        except Exception as e:
            print(f"❌ ERROR: {verify_func.__name__} の実行に失敗: {e}")
            print()

    # サマリー
    print("=" * 80)
    passed_count = sum(1 for r in results if r.passed)
    total_count = len(results)
    print(f"SUMMARY: {passed_count}/{total_count} passed")
    print()

    if passed_count == total_count:
        print("判定: ✅ リポジトリの存在意義が検証された")
        print()
        print("主要な機能が正しく実装されています：")
        print("  • 13種類のAI Actionsが提供されている")
        print("  • 全ActionにExampleとInstructionが存在")
        print("  • Dry Run検証ワークフローが実装されている")
        print("  • プライバシーを考慮したテレメトリー収集")
        print("  • AIレビュー受入率の追跡機能")
    else:
        print("判定: ⚠️  存在意義の一部に改善の余地あり")
        print()
        print("改善が必要な項目：")
        for r in results:
            if not r.passed:
                print(f"  • {r.function_id}: {r.interpretation}")

    # 結果をJSONで保存
    output_path = Path(".audit/output/verification_result.json")
    output_path.parent.mkdir(parents=True, exist_ok=True)

    # JSONシリアライズ可能な形式に変換
    results_serializable = []
    for r in results:
        result_dict = asdict(r)
        # Noneのファイル参照を除外
        if r.file_references:
            result_dict["file_references"] = [f for f in r.file_references if f is not None]
        else:
            result_dict["file_references"] = []
        results_serializable.append(result_dict)

    output_path.write_text(
        json.dumps(results_serializable, ensure_ascii=False, indent=2),
        encoding="utf-8"
    )

    print()
    print(f"詳細レポートを保存: {output_path}")

    sys.exit(0 if passed_count == total_count else 1)


if __name__ == "__main__":
    main()
